### Video
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers ](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Panda-70M_Captioning_70M_Videos_with_Multiple_Cross-Modality_Teachers_CVPR_2024_paper.html)| ![29577](https://github.com/HeChengHui/CVPR2024/assets/84503515/004faf42-3fa0-41cc-abde-012276cb8ffc)| [![GitHub](https://img.shields.io/github/stars/snap-research/Panda-70M?style=social)](https://github.com/snap-research/Panda-70M)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m2NQ5k1oTcs)
| ‚≠ê[MM-Narrator: Narrating Long-form Videos with Multimodal In-Context Learning ](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_MM-Narrator_Narrating_Long-form_Videos_with_Multimodal_In-Context_Learning_CVPR_2024_paper.html)| ![30881](https://github.com/HeChengHui/CVPR2024/assets/84503515/35f5c232-2798-4f2f-a55a-26422ad916e5)| [![Github Pages](https://img.shields.io/badge/github%20pages-121013?style=for-the-badge&logo=github&logoColor=white)](https://mm-narrator.github.io/) <br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oC1maLnztmo)

---

### Image
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [Segment and Caption Anything ](https://openaccess.thecvf.com/content/CVPR2024/html/Huang_Segment_and_Caption_Anything_CVPR_2024_paper.html)|![29271](https://github.com/HeChengHui/CVPR2024/assets/84503515/788cea16-defc-46bd-8993-3443d7e1d187)| [![GitHub](https://img.shields.io/github/stars/xk-huang/segment-caption-anything?style=social)](https://github.com/xk-huang/segment-caption-anything)
