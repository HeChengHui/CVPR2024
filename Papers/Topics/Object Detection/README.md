|Title|Poster|Resources|Pic|
|------|------|------|------|
| [DETRs Beat YOLOs on Real-time Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.html)|![31301](https://github.com/HeChengHui/CVPR2024/assets/84503515/051f78c9-291c-477e-a165-97ea3854b88e)| [![GitHub](https://img.shields.io/github/stars/lyuwenyu/RT-DETR?style=social)](https://github.com/lyuwenyu/RT-DETR)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UOc0qMSX4Ac)
|[Salience DETR: Enhancing Detection Transformer with Hierarchical Salience Filtering Refinement](https://openaccess.thecvf.com/content/CVPR2024/html/Hou_Salience_DETR_Enhancing_Detection_Transformer_with_Hierarchical_Salience_Filtering_Refinement_CVPR_2024_paper.html)| ![image](https://github.com/HeChengHui/CVPR2024/assets/84503515/a9e39da7-b5de-4ba7-838e-06c3acbfa2a7)| [![GitHub](https://img.shields.io/github/stars/xiuqhou/Salience-DETR?style=social)](https://github.com/xiuqhou/Salience-DETR)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/20240620_182012.jpg)

---

### Open-Vocabulary Object Detection
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ⭐[SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_SHiNe_Semantic_Hierarchy_Nexus_for_Open-vocabulary_Object_Detection_CVPR_2024_paper.html)|![31092](https://github.com/HeChengHui/CVPR2024/assets/84503515/0dc66158-5475-44b6-8d37-a4ffccc05401)| [![GitHub](https://img.shields.io/github/stars/naver/shine?style=social)](https://github.com/naver/shine)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=T36R4BOKcqg)
| [Generative Region-Language Pretraining for Open-Ended Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Lin_Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection_CVPR_2024_paper.html)| |[![GitHub](https://img.shields.io/github/stars/FoundationVision/GenerateU?style=social)](https://github.com/FoundationVision/GenerateU)|![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-05%20at%2014.27.37.jpeg)
| [Taming Self-Training for Open-Vocabulary Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Zhao_Taming_Self-Training_for_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html)| ![29999](https://github.com/HeChengHui/CVPR2024/assets/84503515/930134e7-957d-43b4-a3e5-7b6730c3a712)| [![GitHub](https://img.shields.io/github/stars/xiaofeng94/SAS-Det?style=social)](https://github.com/xiaofeng94/SAS-Det)|
|  [Language-conditioned Detection Transformer ](https://openaccess.thecvf.com/content/CVPR2024/html/Cho_Language-conditioned_Detection_Transformer_CVPR_2024_paper.html)| |[![GitHub](https://img.shields.io/github/stars/janghyuncho/DECOLA?style=social)](https://github.com/janghyuncho/DECOLA)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-07%20at%2000.26.27.jpeg)
| [YOLO-World: Real-Time Open-Vocabulary Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Cheng_YOLO-World_Real-Time_Open-Vocabulary_Object_Detection_CVPR_2024_paper.html)|<img width="2560" alt="30009" src="https://github.com/HeChengHui/CVPR2024/assets/84503515/8fba3a19-02c9-4491-b5fb-2acf1704a903">| [![GitHub](https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social)](https://github.com/AILab-CVC/YOLO-World)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_qrA1wK9lPw)

---

### Object Recognition
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ⭐[Object Recognition as Next Token Prediction ](https://openaccess.thecvf.com/content/CVPR2024/html/Yue_Object_Recognition_as_Next_Token_Prediction_CVPR_2024_paper.html)| ![31732](https://github.com/HeChengHui/CVPR2024/assets/84503515/445430f7-d486-4423-af3e-9e37746117da)| [![GitHub](https://img.shields.io/github/stars/kaiyuyue/nxtp?style=social)](https://github.com/kaiyuyue/nxtp)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xeI8dZIpoco)

---

### Counting
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ⭐[ Referring Expression Counting ](https://openaccess.thecvf.com/content/CVPR2024/html/Dai_Referring_Expression_Counting_CVPR_2024_paper.html)| ![31344](https://github.com/HeChengHui/CVPR2024/assets/84503515/35ef337f-643c-4b0e-a793-3399fb6dda59)| [![GitHub](https://img.shields.io/github/stars/sydai/referring-expression-counting?style=social)](https://github.com/sydai/referring-expression-counting)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=89hU2xFkYfo)
|  [CrowdDiff: Multi-hypothesis Crowd Density Estimation using Diffusion Models ](https://openaccess.thecvf.com/content/CVPR2024/html/Ranasinghe_CrowdDiff_Multi-hypothesis_Crowd_Density_Estimation_using_Diffusion_Models_CVPR_2024_paper.html)| ![31540](https://github.com/HeChengHui/CVPR2024/assets/84503515/247cd178-d9fd-4141-b0f3-4f67d7af87c6)| [![GitHub](https://img.shields.io/github/stars/dylran/crowddiff?style=social)](https://github.com/dylran/crowddiff)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bwZlwSOetyo)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-04%20at%2018.15.27.jpeg)
| [Weakly Supervised Video Individual Counting ](https://openaccess.thecvf.com/content/CVPR2024/html/Liu_Weakly_Supervised_Video_Individual_Counting_CVPR_2024_paper.html)| ![29221](https://github.com/HeChengHui/CVPR2024/assets/84503515/9bf602d9-5c7f-4080-96d1-13321c35b659)| [![GitHub](https://img.shields.io/github/stars/streamer-AP/CGNet?style=social)](https://github.com/streamer-AP/CGNet)
| [Learning to Count without Annotations ](https://openaccess.thecvf.com/content/CVPR2024/html/Knobel_Learning_to_Count_without_Annotations_CVPR_2024_paper.html)| ![29476](https://github.com/HeChengHui/CVPR2024/assets/84503515/50e721dc-a466-4713-becd-47352fd59044)| [![GitHub](https://img.shields.io/github/stars/lukasknobel/SelfCollages?style=social)](https://github.com/lukasknobel/SelfCollages)|![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-09%20at%2023.45.40.jpeg)
| [DAVE - A Detect-and-Verify Paradigm for Low-Shot Counting ](https://openaccess.thecvf.com/content/CVPR2024/html/Pelhan_DAVE_-_A_Detect-and-Verify_Paradigm_for_Low-Shot_Counting_CVPR_2024_paper.html)| |[![GitHub](https://img.shields.io/github/stars/jerpelhan/DAVE?style=social)](https://github.com/jerpelhan/DAVE)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RgeVvv371JM)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-10%20at%2000.19.02.jpeg)
| [Single Domain Generalization for Crowd Counting ](https://openaccess.thecvf.com/content/CVPR2024/html/Peng_Single_Domain_Generalization_for_Crowd_Counting_CVPR_2024_paper.html)| ![image](https://github.com/user-attachments/assets/adf1c07c-5d22-4d65-b3a7-06eb321a2f39)|[![GitHub](https://img.shields.io/github/stars/Shimmer93/MPCount?style=social)](https://github.com/Shimmer93/MPCount)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=muhC5Po-SU0)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-12%20at%2016.55.02.jpeg)
| [Regressor-Segmenter Mutual Prompt Learning for Crowd Counting ](https://openaccess.thecvf.com/content/CVPR2024/html/Guo_Regressor-Segmenter_Mutual_Prompt_Learning_for_Crowd_Counting_CVPR_2024_paper.html)| |[![GitHub](https://img.shields.io/github/stars/csguomy/mPrompt?style=social)](https://github.com/csguomy/mPrompt)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fvrzpOuBJ_U)

---

### Monocular 3D Object Detection
|Title|Poster|Resources|Pic|
|------|------|------|------|
|  [MonoCD: Monocular 3D Object Detection with Complementary Depths ](https://openaccess.thecvf.com/content/CVPR2024/html/Yan_MonoCD_Monocular_3D_Object_Detection_with_Complementary_Depths_CVPR_2024_paper.html)| ![Poster](https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30921.png?t=1716776068.9816232) | [![GitHub](https://img.shields.io/github/stars/elvintanhust/MonoCD?style=social)](https://github.com/elvintanhust/MonoCD)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-9nvB4eXHI8)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/3D/assets/WhatsApp%20Image%202024-07-04%20at%2016.20.41.jpeg)

---

### Test-Time Adaptation
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [What How and When Should Object Detectors Update in Continually Changing Test Domains? ](https://openaccess.thecvf.com/content/CVPR2024/html/Yoo_What_How_and_When_Should_Object_Detectors_Update_in_Continually_CVPR_2024_paper.html)| ![29997](https://github.com/HeChengHui/CVPR2024/assets/84503515/0656ce8b-a1fb-43a7-ac26-5d6b780c3436)|[![GitHub](https://img.shields.io/github/stars/natureyoo/ContinualTTA_ObjectDetection?style=social)](https://github.com/natureyoo/ContinualTTA_ObjectDetection)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=awhLEXstYVY)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-10%20at%2000.25.27.jpeg)

---

### Training
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [Boosting Object Detection with Zero-Shot Day-Night Domain Adaptation ](https://openaccess.thecvf.com/content/CVPR2024/html/Du_Boosting_Object_Detection_with_Zero-Shot_Day-Night_Domain_Adaptation_CVPR_2024_paper.html)| ![29448](https://github.com/HeChengHui/CVPR2024/assets/84503515/1eb6b162-7793-4820-ba3c-8512b938bccd) | [![GitHub](https://img.shields.io/github/stars/ZPDu/DAI-Net?style=social)](https://github.com/ZPDu/DAI-Net) <br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=X44b2lInZzk)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-04%20at%2018.04.21.jpeg)
| [CAT: Exploiting Inter-Class Dynamics for Domain Adaptive Object Detection ](https://openaccess.thecvf.com/content/CVPR2024/html/Kennerley_CAT_Exploiting_Inter-Class_Dynamics_for_Domain_Adaptive_Object_Detection_CVPR_2024_paper.html)| ![29692](https://github.com/HeChengHui/CVPR2024/assets/84503515/ccc14777-cd8f-4257-b738-9ac029dbc3c9)| [![GitHub](https://img.shields.io/github/stars/mecarill/classawareteacher?style=social)](https://github.com/mecarill/classawareteacher)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Otux0oj3VXA)| ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Object%20Detection/assets/WhatsApp%20Image%202024-07-07%20at%2000.03.24.jpeg)
|[Improving Single Domain-Generalized Object Detection: A Focus on Diversification and Alignment](https://openaccess.thecvf.com/content/CVPR2024/html/Danish_Improving_Single_Domain-Generalized_Object_Detection_A_Focus_on_Diversification_and_CVPR_2024_paper.html)| ![image](https://github.com/HeChengHui/CVPR2024/assets/84503515/57634aeb-4a25-49f0-946e-fc10a741969a)| [![GitHub](https://img.shields.io/github/stars/msohaildanish/DivAlign?style=social)](https://github.com/msohaildanish/DivAlign)

---

### Synthetic Dataset Generation
|Title|Poster|Resources|Pic|
|------|------|------|------|
|[ InstaGen: Enhancing Object Detection by Training on Synthetic Dataset ](https://openaccess.thecvf.com/content/CVPR2024/html/Feng_InstaGen_Enhancing_Object_Detection_by_Training_on_Synthetic_Dataset_CVPR_2024_paper.html)| ![29588](https://github.com/HeChengHui/CVPR2024/assets/84503515/f7c5696c-ed2f-4926-abcf-2b1b0fce3074)| [![GitHub](https://img.shields.io/github/stars/fcjian/InstaGen?style=social)](https://github.com/fcjian/InstaGen)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kOMYenofFNw)
