1. Mulitmodal LLM

---

### Mulitmodal LLM
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ⭐[Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision Language Audio and Action ](https://openaccess.thecvf.com/content/CVPR2024/html/Lu_Unified-IO_2_Scaling_Autoregressive_Multimodal_Models_with_Vision_Language_Audio_CVPR_2024_paper.html)|![29572](https://github.com/HeChengHui/CVPR2024/assets/84503515/3b1feb81-c59a-466d-8ed4-953d2cc17806)| [![GitHub](https://img.shields.io/github/stars/allenai/unified-io-2?style=social)](https://github.com/allenai/unified-io-2)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0CRPI2W_jow)
| [UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio Video Point Cloud Time-Series and Image Recognition ](https://openaccess.thecvf.com/content/CVPR2024/html/Ding_UniRepLKNet_A_Universal_Perception_Large-Kernel_ConvNet_for_Audio_Video_Point_CVPR_2024_paper.html)| ![Poster](https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/29635.png?t=1717351949.273675) | [![GitHub](https://img.shields.io/github/stars/AILab-CVC/UniRepLKNet?style=social)](https://github.com/AILab-CVC/UniRepLKNet)
| [OneLLM: One Framework to Align All Modalities with Language ](https://openaccess.thecvf.com/content/CVPR2024/html/Han_OneLLM_One_Framework_to_Align_All_Modalities_with_Language_CVPR_2024_paper.html)| ![31234](https://github.com/HeChengHui/CVPR2024/assets/84503515/2741f626-f19a-47a7-be5e-1b0cf7bf62bc)| [![GitHub](https://img.shields.io/github/stars/csuhan/OneLLM?style=social)](https://github.com/csuhan/OneLLM)<br> [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HJXsJStn7I4)
| [ModaVerse: Efficiently Transforming Modalities with LLMs ](https://openaccess.thecvf.com/content/CVPR2024/html/Wang_ModaVerse_Efficiently_Transforming_Modalities_with_LLMs_CVPR_2024_paper.html)| ![30292](https://github.com/HeChengHui/CVPR2024/assets/84503515/abed4ae4-9c32-4a15-b9f1-326392244a1a)| [![GitHub](https://img.shields.io/github/stars/xinke-wang/ModaVerse?style=social)](https://github.com/xinke-wang/ModaVerse)

---

### Dataset
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ⭐[MMSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos ](https://openaccess.thecvf.com/content/CVPR2024/html/Qiu_MMSum_A_Dataset_for_Multimodal_Summarization_and_Thumbnail_Generation_of_CVPR_2024_paper.html)||[![GitHub](https://img.shields.io/github/stars/Jason-Qiu/MMSum_model?style=social)](https://github.com/Jason-Qiu/MMSum_model)

---

### Others
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [X-VILA: Cross-Modality Alignment for Large Language Model](https://arxiv.org/abs/2405.19335)| ||![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Multimodal/assets/WhatsApp%20Image%202024-07-12%20at%2016.45.45.jpeg)
