Gaze stuff quite little, so i put these in first even though no code.
1. [Gaze Estimation](https://github.com/HeChengHui/CVPR2024/tree/main/Papers/Topics/Gaze#gaze-estimation)
2. [Gaze Following](https://github.com/HeChengHui/CVPR2024/tree/main/Papers/Topics/Gaze#gaze-following)

---

### Gaze Estimation
|Title|Poster|Resources|Pic|
|------|------|------|------|
| ‚≠ê[From Feature to Gaze: A Generalizable Replacement of Linear Layer for Gaze Estimation](https://openaccess.thecvf.com/content/CVPR2024/html/Bao_From_Feature_to_Gaze_A_Generalizable_Replacement_of_Linear_Layer_CVPR_2024_paper.html) | ![Poster](https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30094.png?t=1717303581.092683) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=A_1zfmAw6Dk)
| [Unsupervised Gaze Representation Learning from Multi-view Face Images](https://openaccess.thecvf.com/content/CVPR2024/html/Bao_Unsupervised_Gaze_Representation_Learning_from_Multi-view_Face_Images_CVPR_2024_paper.html) |  ![Poster](https://cvpr.thecvf.com/media/PosterPDFs/CVPR%202024/30636.png?t=1717303629.637033) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E48NxWt6034)

---

### Gaze Following
|Title|Poster|Resources|Pic|
|------|------|------|------|
| [Sharingan: A Transformer Architecture for Multi-Person Gaze Following](https://openaccess.thecvf.com/content/CVPR2024/html/Tafasca_Sharingan_A_Transformer_Architecture_for_Multi-Person_Gaze_Following_CVPR_2024_paper.html) | |[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-z92XQmZaqA) | ![Pic](https://github.com/HeChengHui/CVPR2024/blob/main/Papers/Topics/Gaze/assets/WhatsApp%20Image%202024-07-03%20at%2013.21.52.jpeg)

